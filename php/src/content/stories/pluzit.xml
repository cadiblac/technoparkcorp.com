<?xml version="1.0"?>
<!--
 *
 * Copyright (c) 2008, TechnoPark Corp., Florida, USA
 * All rights reserved. THIS IS PRIVATE SOFTWARE.
 *
 * Redistribution and use in source and binary forms, with or without modification, are PROHIBITED
 * without prior written permission from the author. This product may NOT be used anywhere
 * and on any computer except the server platform of TechnoPark Corp. located at
 * www.technoparkcorp.com. If you received this code accidentally and without intent to use
 * it, please report this incident to the author by email: privacy@technoparkcorp.com or
 * by mail: 568 Ninth Street South 202 Naples, Florida 34102, the United States of America,
 * tel. +1 (239) 243 0206, fax +1 (239) 236-0738.
 *
-->

<article>

<categories>

	<category>User Acceptance Testing</category>
	<category>Manual Testing</category>
	<category>Risk Management</category>
	<category>Risk Mitigation</category>

</categories>

<title>User acceptance testing instead of manual testing, sometimes it works</title>
<label></label>
<intro></intro>
<next></next>
<invisible/>

<description>

	There was a difficult web 2.0 system which was estimated in 1100 staff-hours. None of 
	the three previous software companies accepted that system due to several reasons, one 
	of them was -- the client. He likes to test only the whole system with a detailed  
	evaluation of each element.

</description>

<tex>

	After deep analysis two main risks for the project appeared -- normal completion of 
	the whole project itself and elaboration of clear SRS.

	The strategy for the key risks was mitigation. We had spent almost 1/3 of the total 
	management cost for elaboration risk strategy and prediction of effects.

	Near to the end of schedule when the system was implemented (all 130 requirements 
	were tested) we moved to stress and volume tests.  50 to 
	200 staff-hours were spent for those tests.

	Then "acceptance testing" followed. As mitigation for key risks we 
	spent \emph{150 (!)} staff hours for acceptance testing. The whole system was
	deployed on a test-platform and provided to the customer. As planned, the customer began 
	to make different remarks here and there, which were not in the SRS and were 
	not important for functionality itself, but should be fixed any way as the 
	customer said. With automatic and manual testing we found around 50 bugs, 
	but the customer found around 100 small and big remarks. 
	All his issues were registered as bugs and were fixed ASAP to start testing again.

	So, in total, risk management was correct and helped us to develop 
	and send that system.

	The 150 staff-hours that were spent for acceptance testing were nothing near the
	big loses that could have happened to our company if we had done manual 
	and automatic testing.

	As a result, the customer received his system and our company spent 
	only that money that we planned at the beginning.

</tex>

</article>

